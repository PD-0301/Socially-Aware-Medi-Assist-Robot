# A Platform for Socially Aware Medi-Assist Robot  

## Overview  
This project focuses on the development of a medical robot platform for hospital environments, initially manually controlled but designed to transition into a fully autonomous system. The robot integrates multiple sensors, including an Inertial Measurement Unit (IMU), Global Positioning System (GPS), tachometer, and radar sensors, enabling efficient navigation and interaction.  

## Features  
- **Manual Control**: Operated via an Xbox controller with a custom-designed GUI.  
- **Sensor Integration**: IMU for stability, GPS for location tracking, tachometer for speed monitoring, and radar for real-time obstacle detection.  
- **Wireless Communication**: Live data streaming to a laptop interface.  
- **Real-Time Monitoring**: Video feed, speed control, and interactive voice feedback.  

## Radar Implementations  
- **Obstacle Detection & Avoidance**: Radar sensors help the robot detect objects in real-time and avoid collisions.  
- **Environment Mapping**: Using radar for SLAM (Simultaneous Localization and Mapping) to enhance autonomous navigation.  
- **Human Presence Recognition**: Radar assists in identifying human movement for improved hospital interactions.  

## Future Enhancements  
- **Autonomous Navigation**: Implementing path planning and obstacle avoidance.  
- **AI-Based Object Detection**: Enhancing recognition accuracy using deep learning.  
- **Visual SLAM**: Utilizing camera and radar-based mapping for improved localization.  
- **Energy Optimization**: Reducing power consumption for extended operation.  

## Expected Impact  
This medical robot platform aims to enhance hospital efficiency, reduce staff workload, and improve patient engagement. The combination of sensor fusion, AI, and automation makes it a scalable solution for various healthcare applications.  
